{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a decision tree approach to trade data supplied by Jane Street in a Kaggle Machine Learning competition: https://www.kaggle.com/c/jane-street-market-prediction\n",
    "There are 130 anonymized, normalized features for each row of data respresenting possible trades. The return over various time horizons is also supplied, as well as weights for each trade. Using machine learning, the aim is to create an online version of an algorithm created with the test data. \n",
    "Due to the immense size of the dataset, I will be using kdb in my exploratory analysis and model selection/fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Welcome to quantQ\r\n",
      "   ____ \\ \\   \r\n",
      "  / ___| \\ \\  \r\n",
      " | |_| |  ) )   \r\n",
      "  \\__  | / /   \r\n",
      "     |_|/ /     \r\n",
      "\r\n",
      "For available sub-namespaces, type key`.quantQ:\r\n",
      "()\n",
      "\r\n",
      "For functions in a namespace, type .e.g \\f .quantQ.rf\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "\\c 100 100\n",
    "\\cd C:\\q\\w32\\\n",
    "\n",
    "/ Import Python libraries\n",
    "\\l p.q\n",
    "/import several ml libraries\n",
    "\\l quantQ\\lib\\quantQjupyterq.q\n",
    "\\l mlnotebooks\\utils\\graphics.q\n",
    "\\l automl\\automl.q\n",
    "\n",
    "\n",
    "\\l ml\\ml.q\n",
    "\n",
    "\\l mlnotebooks\\utils\\graphics.q\n",
    "\\l mlnotebooks\\utils\\util.q\n",
    "/Fun Q ml library\n",
    "\\l funq\\funqJQ.q\n",
    "/graphing \n",
    "\\l embedPy\\examples\\importmatplotlib.q\n",
    "plt:.matplotlib.pyplot[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature  | tag_0 tag_1 tag_2 tag_3 tag_4 tag_5 tag_6 tag_7 tag_8 tag_9 tag_10 tag_11 tag_12 tag_1..\r\n",
      "---------| --------------------------------------------------------------------------------------..\r\n",
      "feature_0| 0     0     0     0     0     0     0     0     0     0     0      0      0      0    ..\r\n",
      "feature_1| 0     0     0     0     0     0     1     1     0     0     0      0      0      0    ..\r\n",
      "feature_2| 0     0     0     0     0     0     1     1     0     1     0      0      0      0    ..\r\n",
      "feature_3| 0     0     0     0     0     0     1     0     1     0     0      0      0      0    ..\r\n",
      "feature_4| 0     0     0     0     0     0     1     0     1     1     0      0      0      0    ..\r\n",
      "feature_5| 0     0     0     0     0     0     1     0     0     0     1      0      0      0    ..\r\n",
      "feature_6| 0     0     0     0     0     0     1     0     0     1     1      0      0      0    ..\r\n",
      "feature_7| 0     0     0     0     1     0     1     0     0     0     0      1      0      0    ..\r\n",
      "feature_8| 0     0     0     0     1     0     1     0     0     1     0      1      0      0    ..\r\n",
      "feature_9| 1     0     0     0     0     0     1     0     0     0     0      1      0      0    ..\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "`features\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//A True/false table is given for our 130 features\n",
    "features:(\"SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS\";enlist\",\") 0: `:C:/MLProjects/JaneStreetMarketPrediction/features.csv\n",
    "features:(select feature from features) ,'(flip 1_flip features = `TRUE)\n",
    "`feature xkey `features \n",
    "features:\"f\"$features\n",
    "show 10#features\n",
    "\n",
    "//1 for true, 0 for false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "//load 500 days of trade data\n",
    "t:(\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\";enlist\",\") 0: `:C:/MLProjects/JaneStreetMarketPrediction/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`t\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//key the table based on date\n",
    "`date xkey `t\n",
    "//apply sort attribute on tablee t\n",
    "`s#t;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "//I wish to see the cumulative behavior of the asset and the corresponding features\n",
    "\n",
    "sumTable:((sum select from t where date = 0);(sum select from t where date = 1))\n",
    "`sumTable upsert (sum select from t where date = 3);\n",
    "`sumTable upsert (sum select from t where date = 4);\n",
    "`sumTable upsert (sum select from t where date = 5);\n",
    "`sumTable upsert (sum select from t where date = 6);\n",
    "`sumTable upsert (sum select from t where date = 7);\n",
    "`sumTable upsert (sum select from t where date = 8);\n",
    "`sumTable upsert (sum select from t where date = 9);\n",
    "`sumTable upsert (sum select from t where date = 10);\n",
    "`sumTable upsert (sum select from t where date = 11);\n",
    "`sumTable upsert (sum select from t where date = 12);\n",
    "`sumTable upsert (sum select from t where date = 13);\n",
    "`sumTable upsert (sum select from t where date = 14);\n",
    "`sumTable upsert (sum select from t where date = 15);\n",
    "`sumTable upsert (sum select from t where date = 16);\n",
    "`sumTable upsert (sum select from t where date = 17);\n",
    "`sumTable upsert (sum select from t where date = 18);\n",
    "`sumTable upsert (sum select from t where date = 19);\n",
    "`sumTable upsert (sum select from t where date = 20);\n",
    "`sumTable upsert (sum select from t where date = 21);\n",
    "`sumTable upsert (sum select from t where date = 22);\n",
    "`sumTable upsert (sum select from t where date = 23);\n",
    "`sumTable upsert (sum select from t where date = 24);\n",
    "`sumTable upsert (sum select from t where date = 25);\n",
    "`sumTable upsert (sum select from t where date = 26);\n",
    "`sumTable upsert (sum select from t where date = 27);\n",
    "`sumTable upsert (sum select from t where date = 28);\n",
    "`sumTable upsert (sum select from t where date = 29);\n",
    "`sumTable upsert (sum select from t where date = 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sumTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           | weight    resp_1      resp_2      resp_3      resp_4       resp        feature_0   f..\r\n",
       "------     | ------------------------------------------------------------------------------------..\r\n",
       "weight     | 1         0.6502968   0.528533    0.3907316   0.2438018    0.2132593   0.2166088   0..\r\n",
       "feature_19 | 0.872508  0.6556457   0.5557137   0.4160078   0.2823856    0.2553343   0.5737334   0..\r\n",
       "feature_64 | 0.8711671 0.4586867   0.3349088   0.2106426   0.1041159    0.08065981  0.336871    0..\r\n",
       "feature_41 | 0.8677441 0.7555867   0.6386575   0.4018487   0.2784457    0.2846957   0.1667631   0..\r\n",
       "feature_25 | 0.8597158 0.6307746   0.5306731   0.3980631   0.2615406    0.2317849   0.605812    0..\r\n",
       "feature_107| 0.8400914 0.57538     0.4568117   0.2237389   0.09752889   0.09834594  0.3041786   0..\r\n",
       "feature_95 | 0.8344078 0.5379437   0.4054576   0.1679591   0.03998059   0.03881176  0.2824864   0..\r\n",
       "feature_119| 0.8323594 0.554094    0.430159    0.1932024   0.06658764   0.06732719  0.3017375   0..\r\n",
       "feature_52 | 0.8322053 0.7138857   0.561281    0.346992    0.2412107    0.2338121   0.267147    0..\r\n",
       "feature_23 | 0.8208382 0.5894843   0.4955957   0.3781664   0.2381713    0.2052359   0.6535905   0..\r\n",
       "feature_53 | 0.8203395 0.6430849   0.4993853   0.2882734   0.1948525    0.1919355   0.199873    0..\r\n",
       "feature_122| 0.8193132 0.6553806   0.5104228   0.2912792   0.1963031    0.1952784   0.1873625   0..\r\n",
       "feature_11 | 0.8168351 0.5764205   0.4790728   0.3017178   0.1503404    0.1348454   0.1297907   0..\r\n",
       "feature_124| 0.8154871 0.6604338   0.5183142   0.2976284   0.2019858    0.2019221   0.1814611   0..\r\n",
       "feature_29 | 0.8153542 0.5453119   0.3883707   0.1580335   0.07608321   0.08289691  -0.06648332 0..\r\n",
       "feature_69 | 0.8135541 0.4940955   0.3647113   0.2416448   0.1508985    0.1271877   0.2077505   0..\r\n",
       "feature_1  | 0.8127781 0.5769877   0.4285193   0.2712809   0.1855797    0.1674987   0.2090224   1..\r\n",
       "feature_128| 0.8112508 0.6482059   0.5029193   0.2825368   0.1888772    0.1886486   0.1801116   0..\r\n",
       "feature_120| 0.8035095 0.6720422   0.5320345   0.3019619   0.2110936    0.2159778   0.1628047   0..\r\n",
       "feature_126| 0.8009024 0.643066    0.4978996   0.2761964   0.1835266    0.1840133   0.1761198   0..\r\n",
       "feature_102| 0.7986406 0.5099057   0.3820202   0.1575643   0.03810878   0.03540216  0.3496177   0..\r\n",
       "feature_45 | 0.7937774 0.564309    0.4138283   0.1960635   0.1100136    0.1085608   0.3665175   0..\r\n",
       "feature_33 | 0.7936255 0.4914605   0.3371602   0.1116628   0.02492357   0.02981146  -0.1186776  0..\r\n",
       "feature_114| 0.7905288 0.4844065   0.3517111   0.1224029   0.004359326  0.002738031 0.3250491   0..\r\n",
       "feature_9  | 0.7879944 0.5158105   0.3833531   0.2227105   0.1271263    0.1124875   0.2309289   0..\r\n",
       "feature_90 | 0.7866559 0.4679786   0.3287445   0.09351705  -0.02330488  -0.02397222 0.2922853   0..\r\n",
       "feature_15 | 0.7828955 0.4808909   0.3529908   0.1999064   0.1034812    0.08816841  0.2262598   0..\r\n",
       "feature_35 | 0.781287  0.4938448   0.3365553   0.1137339   0.03789738   0.04445297  -0.1291742  0..\r\n",
       "feature_103| 0.7786842 0.4660151   0.3675793   0.1977994   0.09085028   0.08424897  0.4987202   0..\r\n",
       "feature_31 | 0.7737307 0.4675222   0.3223793   0.1072149   0.01574926   0.01883595  -0.2169129  0..\r\n",
       "feature_51 | 0.7710006 0.5326324   0.415618    0.3805336   0.2866444    0.2404102   0.4019156   0..\r\n",
       "feature_66 | 0.7703708 0.5821464   0.5471933   0.439103    0.3675372    0.3666684   0.3615056   0..\r\n",
       "feature_94 | 0.7671178 0.3731738   0.2381453   0.01821457  -0.07673124  -0.07044272 0.2126265   0..\r\n",
       "feature_104| 0.7651402 0.4501712   0.3306334   0.1118454   -0.008457766 -0.01127198 0.3854525   0..\r\n",
       "feature_105| 0.7600881 0.4297171   0.3149946   0.1101504   -0.008460517 -0.0135019  0.4117691   0..\r\n",
       "feature_106| 0.7595158 0.4326148   0.3234631   0.1409282   0.03082777   0.02390905  0.4855073   0..\r\n",
       "feature_116| 0.7587495 0.4243175   0.2945014   0.06994516  -0.04524626  -0.04657116 0.3263509   0..\r\n",
       "feature_92 | 0.7583665 0.408632    0.2717163   0.04051074  -0.0726351   -0.07284106 0.2921482   0..\r\n",
       "feature_91 | 0.7557556 0.3656464   0.2373162   0.01588739  -0.0699508   -0.05754058 0.09778322  0..\r\n",
       "feature_93 | 0.7515916 0.3751013   0.2416017   0.01599551  -0.0933285   -0.09208815 0.2689621   0..\r\n",
       "feature_65 | 0.7380675 0.5677708   0.5396922   0.4407078   0.3762033    0.3761923   0.3620816   0..\r\n",
       "feature_36 | 0.737929  0.590316    0.4840929   0.3576589   0.2832504    0.269783    -0.1234687  0..\r\n",
       "feature_62 | 0.7275983 0.591426    0.5631398   0.530352    0.4357625    0.4093404   0.3759716   0..\r\n",
       "feature_63 | 0.7274598 0.5946391   0.5658214   0.5329527   0.4386967    0.4123079   0.3742295   0..\r\n",
       "feature_7  | 0.7268996 0.6455647   0.6421108   0.6123284   0.4588813    0.415679    0.06834213  0..\r\n",
       "feature_13 | 0.726554  0.4399528   0.3252199   0.1710747   0.05331887   0.03671579  0.2002504   0..\r\n",
       "feature_50 | 0.7263361 0.5121437   0.3714225   0.2003982   0.115005     0.1033986   0.4188035   0..\r\n",
       "feature_30 | 0.7243214 0.622825    0.5235225   0.3934814   0.3216394    0.3116618   -0.1254761  0..\r\n",
       "feature_27 | 0.7217916 0.4786601   0.3573446   0.1597603   0.06272843   0.06429903  -0.3606118  0..\r\n",
       "feature_117| 0.7216852 0.360545    0.2387261   0.02613543  -0.0828809   -0.08303755 0.3256453   0..\r\n",
       "feature_46 | 0.7076092 0.5008241   0.3691137   0.1543973   0.08011335   0.08802642  0.365034    0..\r\n",
       "feature_34 | 0.7026118 0.5397266   0.4414169   0.3241826   0.2472767    0.2324517   -0.1371866  0..\r\n",
       "feature_21 | 0.6588559 0.4806457   0.4355669   0.3704413   0.2402189    0.2069043   0.7723193   0..\r\n",
       "resp_1     | 0.6502968 1           0.968268    0.8324476   0.7146233    0.7086338   0.1345381   0..\r\n",
       "feature_118| 0.6496665 0.2661899   0.1569282   -0.03232629 -0.11717     -0.1114393  0.336031    0..\r\n",
       "feature_42 | 0.6268402 0.4467379   0.3410061   0.1043781   0.05000848   0.07938197  0.1565503   0..\r\n",
       "feature_58 | 0.6082884 0.4944437   0.3070685   0.0795202   0.0209568    0.02680404  -0.06646063 0..\r\n",
       "feature_57 | 0.607429  0.4918061   0.304019    0.07179824  0.0123447    0.01937413  -0.07849407 0..\r\n",
       "feature_59 | 0.6058638 0.4961204   0.3089635   0.08679049  0.02954197   0.03417634  -0.06650246 0..\r\n",
       "feature_56 | 0.595708  0.4899143   0.3055346   0.08148696  0.02945967   0.03644902  -0.0805823  0..\r\n",
       "feature_61 | 0.5952054 0.2515792   0.0744481   -0.05312973 -0.1655122   -0.2027444  0.1439917   0..\r\n",
       "feature_55 | 0.5881749 0.4775345   0.2941397   0.05653785  -0.002914308 0.007014943 -0.1143081  0..\r\n",
       "feature_60 | 0.5843216 0.2476413   0.07237025  -0.0486938  -0.1626103   -0.2019727  0.15492     0..\r\n",
       "feature_17 | 0.582644  0.4895567   0.4870042   0.4927036   0.3738642    0.3308553   0.7717767   0..\r\n",
       "feature_43 | 0.5796819 0.2786621   0.1597874   -0.05659748 -0.1292087   -0.1126307  0.1646046   0..\r\n",
       "feature_115| 0.5660529 0.1906198   0.1055856   -0.05922684 -0.1285418   -0.1179688  0.3136774   0..\r\n",
       "feature_26 | 0.5439555 0.47843     0.4513684   0.4711836   0.3793336    0.332644    0.5340875   0..\r\n",
       "feature_44 | 0.5424709 0.2696457   0.1702167   0.09476536  0.05445753   0.03291588  0.3536792   0..\r\n",
       "feature_20 | 0.5343176 0.4961405   0.4740893   0.4887818   0.4028383    0.3602587   0.5117115   0..\r\n",
       "resp_2     | 0.528533  0.968268    1           0.9033759   0.8050922    0.8055277   0.1071364   0..\r\n",
       "feature_48 | 0.5047723 0.07295438  -0.02511762 -0.1609491  -0.2143693   -0.2119542  0.3374554   0..\r\n",
       "feature_47 | 0.4752474 0.09409866  -0.01219801 -0.1731972  -0.2237816   -0.2135834  0.2014834   0..\r\n",
       "feature_32 | 0.4634751 0.3638477   0.3128154   0.2668913   0.2107487    0.1929517   -0.3945176  0..\r\n",
       "feature_28 | 0.4469733 0.3924701   0.3632222   0.3360002   0.2616927    0.2379821   -0.454558   0..\r\n",
       "feature_24 | 0.4285264 0.3807637   0.3761791   0.4450781   0.3589687    0.3056541   0.5877147   0..\r\n",
       "feature_101| 0.4195392 -0.01460492 -0.02918136 -0.04744443 -0.1474108   -0.1830968  0.2852506   0..\r\n",
       "feature_22 | 0.4155499 0.3850428   0.3991254   0.4691723   0.3847741    0.3366928   0.5191549   0..\r\n",
       "ts_id      | 0.4109253 0.2018886   0.137565    0.004512671 -0.004528703 0.009770941 0.12706     0..\r\n",
       "feature_113| 0.390976  -0.07338204 -0.09740595 -0.0928294  -0.1894488   -0.2327458  0.2472164   0..\r\n",
       "resp_3     | 0.3907316 0.8324476   0.9033759   1           0.9426244    0.9062988   0.1220896   0..\r\n",
       "feature_39 | 0.3863118 0.2087839   0.1348015   0.03919235  0.05450429   0.07119665  -0.696742   0..\r\n",
       "feature_89 | 0.3853254 -0.1103523  -0.1536072  -0.1680545  -0.2672721   -0.3096267  0.2287011   0..\r\n",
       "feature_3  | 0.3739765 0.4900601   0.480813    0.3812567   0.4110876    0.4438375   -0.286321   0..\r\n",
       "feature_123| 0.3551154 0.361511    0.2657361   0.2790892   0.2146021    0.1618545   0.09226201  0..\r\n",
       "feature_54 | 0.3521743 0.3432558   0.2818908   0.3395902   0.2749527    0.216057    0.09699669  0..\r\n",
       "feature_68 | 0.3454212 0.01655197  -0.1383935  -0.306755   -0.3452975   -0.3399677  -0.0826182  0..\r\n",
       "feature_67 | 0.3386416 0.01222866  -0.1423955  -0.3104564  -0.3479527   -0.3423094  -0.08584666 0..\r\n",
       "feature_129| 0.3374206 0.3474047   0.2524624   0.2691717   0.2075945    0.1548615   0.0800623   0..\r\n",
       "feature_121| 0.3117212 0.38528     0.2970655   0.3057678   0.2487976    0.2015614   0.045481    0..\r\n",
       "feature_127| 0.3061041 0.3314046   0.2392485   0.2624314   0.2029702    0.1495355   0.06278557  0..\r\n",
       "feature_125| 0.2778496 0.3254296   0.2383342   0.2658294   0.2067623    0.1534001   0.04201196  0..\r\n",
       "feature_37 | 0.262651  0.4105984   0.4615995   0.4958051   0.4251646    0.3998778   0.7468264   0..\r\n",
       "resp_4     | 0.2438018 0.7146233   0.8050922   0.9426244   1            0.9897218   0.05376156  0..\r\n",
       "feature_0  | 0.2166088 0.1345381   0.1071364   0.1220896   0.05376156   0.01860869  1           0..\r\n",
       "resp       | 0.2132593 0.7086338   0.8055277   0.9062988   0.9897218    1           0.01860869  0..\r\n",
       "feature_4  | 0.1736826 0.3562343   0.3883117   0.4020867   0.4329041    0.440554    -0.2031179  0..\r\n",
       "feature_40 | 0.1700599 0.161927    0.1584178   0.1797368   0.2081916    0.2089839   -0.7376613  0..\r\n",
       "..\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc u cor/:\\:u:flip sumTable\n",
    "//If we assume cumulative weight is a measure of trading activity, then features 19, 64, 41, 25, 107... correlate with vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resp_1| 63.86883\r\n",
       "resp_2| 76.54616\r\n",
       "resp_3| 159.4412\r\n",
       "resp_4| 269.699\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum select resp_1,resp_2,resp_3,resp_4 from sumTable\n",
    "//we see on average that the longer the hold the more profit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428573\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "417952\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count select from t where resp_1 >0, resp<0\n",
    "count select from t where resp_1 <0, resp>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "/\n",
    "There are plenty of trades that start off negative but end positive and vis versa, almost identical counts\n",
    "We will not take trades with positive resp. Instead, we take trades with positive resp_1\n",
    "\n",
    "Rule 1: Don't take any trades with a negative return on 1st time horizon\n",
    "Rule 2: Don't take trades with weight above X\n",
    "Rule 3: End model uses online learning\n",
    "Rule 4: Be prepared for regime change (Identify the change itself, warning signs, and effects)\n",
    "Rule 5: Feature Engineer lagging indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`t\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{[f;x]embedPy[f;x]}[foreign]enlist\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 460.8x345.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update sumresp:sums resp_1 from `t\n",
    "plt.xlabel\"Date\";\n",
    "plt.ylabel\"Price change\";\n",
    "plt.title\"Asset Price (cumulative resp_1)\";\n",
    "plt.grid 1b;\n",
    "plt.scatter[exec sumresp from t;  exec date from t]\n",
    "plt.show[];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "//we see the asset appreciate over time, making most trades profitable\n",
    "//we will likely see very similar trading days. We will try to cluster trading days together later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`t\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//We analyze the data on a per day basis. \n",
    "delete sumresp from `t;\n",
    "day0t:select from t where date=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`day0t\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day0t:0!day0t //unkey\n",
    "delete date, weight, ts_id  from `day0t;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`day0t\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`day0t\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update trade:0 from `day0t;\n",
    "update trade: 1 from `day0t where  resp_1>0;\n",
    "day0t:`trade xcols day0t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`d.train\r\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`d.test\r\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Make decision tree to separate, no time series data leakage\n",
    "d:.ut.part[`train`test!3 1;til] day0t\n",
    "delete resp_1, resp_2, resp_3, resp_4, resp from `d.train\n",
    "delete resp_1, resp_2, resp_3, resp_4, resp from `d.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52398\r\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//random forest, number features used = sqrt n\n",
    "k:20\n",
    "m:.ml.bag[k;.ml.ct[(1#`maxff)!1#sqrt;::]] d.train ///make k decision trees\n",
    "//random forest sqrt features p171\n",
    "max avg d.test.trade = .ml.pbag[1+til k;m] d.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "`delta0t\r\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`delta0.train\r\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "`delta0.test\r\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//at 52.4%, Random Forests with existing data fail as a binary classifier\n",
    "//Instead of predicting trade viability using features, we will use the change in features\n",
    "delta0t:day0t - prev day0t\n",
    "update trade:(exec trade from day0t) from `delta0t\n",
    "delta0t:1_delta0t; //drop first row\n",
    "delta0:.ut.part[`train`test!3 1;til] delta0t\n",
    "delete resp_1, resp_2, resp_3, resp_4, resp from `delta0.train;\n",
    "delete resp_1, resp_2, resp_3, resp_4, resp from `delta0.test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5390122\r\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//random forest, number features used = sqrt n (using delta of features)\n",
    "k:20\n",
    "m:.ml.bag[k;.ml.ct[(1#`maxff)!1#sqrt;::]] delta0.train ///make k decision trees\n",
    "//random forest sqrt features p171\n",
    "max avg delta0.test.trade = .ml.pbag[1+til k;m] delta0.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train| 4190\r\n",
       "test | 1397\r\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (n = 4190, err = 48.9%)\n",
      "|  feature_39 >[;-0.006013617] 0: 1 (n = 2049, err = 40%)\n",
      "|  feature_39 >[;-0.006013617] 1: 0 (n = 2141, err = 42.5%)\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1\r\n"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Running a random forest on the deltas seems to be fruitless as well. \n",
    "//For completeness, we will use adaptive boosting as well.\n",
    "\n",
    "/partition\n",
    "count each d:.ut.part[`train`test!3 1;til] day0t\n",
    "delete resp_1, resp_2, resp_3, resp_4, resp from `d.train;\n",
    "delete resp_1, resp_2, resp_3, resp_4, resp from `d.test;\n",
    "\n",
    "/create decision tree stump to use as a weak classifier\n",
    "stump:.ml.ct[(1#`maxd)!1#1]\n",
    "-1 .ml.ptree[0] stump[::] d.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Our best feature is feature_39 with a 40% error rate\n",
    "//We will run 20 rounds of Adaboost and store model in m\n",
    "k:20\n",
    "m:.ml.fab[k;stump;.ml.pdt] d.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5875895\r\n"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//This is computationally expensive. We check for converging k value before testing\n",
    "P:.ml.pab[1+ til k;.ml.pdt;m] d.train\n",
    "max avg d.train.trade = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5382963\r\n"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//At 58.75% accuracy on training data, it would seem adaboost is a poor fit for the feature data\n",
    "P:.ml.pab[1+ til k;.ml.pdt;m] d.test\n",
    "max avg d.test.trade = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5586059\r\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//53.82% on test data\n",
    "//Let us proceed to use the deltas instead\n",
    "k:20\n",
    "m:.ml.fab[k;stump;.ml.pdt] delta0.train //train model\n",
    "//test model on training data\n",
    "P:.ml.pab[1+ til k;.ml.pdt;m] delta0.train\n",
    "max avg delta0.train.trade = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5382963\r\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//At 55.86% accuracy on training data is very poor. Let us move on to test\n",
    "P:.ml.pab[1+ til k;.ml.pdt;m] delta0.test\n",
    "max avg delta0.test.trade = P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, decision tree algorithms such as Random Forest and AdaBoost performed very poorly on the trade data provided by Jane Street. Although I have seen some decision tree algos perform well on tick data, whatever the features on this dataset represent do not lend themselves to such methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
